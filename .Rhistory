# p-value = 9.45*(10**-7) ,  *** у Fertility означают сильную взаимосвязь Fertility и Examination
model2=lm(Examination~Education,data)
model2
summary(model2)
model1=lm(Examination~Fertility,data)
model1
summary(model1)
model1=lm(Examination~Fertility,data)
model1
summary(model1)
# Оценка по R^2 : модель среднего качества, выдает правильные ответы в 41% случаев
# p-value = 9.45*(10**-7) ,  *** у Fertility означают сильную взаимосвязь Fertility и Examination
#Регрессия y =ax*b для  Examination~Education
model2=lm(Examination~Education,data)
model2
summary(model2)
# Оценка по R^2 : модель среднего качества, выдает правильные ответы в 48% случаев
# p-value = 4.811*(10**-8) ,   *** у Education означают сильную взаимосвязь Education и Examination
#Регрессия y =ax*b для Examination~Fertility
model1=lm(Examination~Fertility,data)
model1
summary(model1)
# Оценка по R^2 : модель среднего качества, выдает правильные ответы в 40% случаев
# p-value = 9.45*(10**-7) ,  *** у Fertility означают сильную взаимосвязь Fertility и Examination
#Fertility и Examination связаны отрицательно
model2=lm(Examination~Education,data)
model2
summary(model2)
# Оценка по R^2 : модель среднего качества, выдает правильные ответы в 47% случаев
# p-value = 4.811*(10**-8) ,   *** у Education означают сильную взаимосвязь Education и Examination
# Education и Examination связаны отрицательно (-0.41)
#Fertility и Examination связаны отрицательно (-0.41)
#Регрессия y =ax*b для  Examination~Education
model2=lm(Examination~Education,data)
model2
summary(model2)
# Оценка по R^2 : модель среднего качества, выдает правильные ответы в 47% случаев
# p-value = 4.811*(10**-8) ,   *** у Education означают сильную взаимосвязь Education и Examination
# Education и Examination связаны положительно (0.57)
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model=lm(mpg~disp+hp+drat,data)
install.packages("car")
library(car)
library("lmtest")
data = na.omit(mtcars)
#1 Исследуем линейную завимсимость регрессоров
model=lm(mpg~cyl+disp+hp+drat,data)
vif(model)#vif самый большой у cyl
summary(lm(disp~cyl+hp+drat,data))#тоже зависим и vif=6.2 > 5
summary(lm(cyl~disp+hp+drat,data))#убеждаемся что больше всех линейно зависим cyl
summary(lm(hp~cyl+disp+drat,data))
summary(lm(drat~disp+hp+cyl,data))
#удаляем cyl из исследования
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model=lm(mpg~disp+hp+drat,data)
summary(model)#R^2=77%,
install.packages("car")
library(car)
library("lmtest")
data = na.omit(mtcars)
#1 Исследуем линейную завимсимость регрессоров
model=lm(mpg~cyl+disp+hp+drat,data)
vif(model)#vif самый большой у cyl
summary(lm(disp~cyl+hp+drat,data))#тоже зависим и vif=6.2 > 5
summary(lm(cyl~disp+hp+drat,data))#убеждаемся что больше всех линейно зависим cyl
summary(lm(hp~cyl+disp+drat,data))
summary(lm(drat~disp+hp+cyl,data))
#удаляем cyl из исследования
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model=lm(mpg~disp+hp+drat,data)
summary(model)#R^2=77%,
#1 Исследуем линейную завимсимость регрессоров
model=lm(mpg~cyl+disp+hp+drat,data)
vif(model)#vif самый большой у cyl
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model=lm(mpg~disp+hp+drat,data)
summary(model)#R^2=77%,
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model=lm(mpg~disp+hp+drat,data)
summary(model)#1)R^2=75% модель очень хороша, 2) хорошим регрессором можно
model=lm(mpg~cyl+disp+hp+drat,data)
model1=lm(mpg~cyl+disp+hp+drat,data)
summary(model1)
#2 Строим парную регрессию с менее зависимыми между собой регрессорами
model2=lm(mpg~disp+hp+drat,data)
summary(model2)#1)R^2=75% модель очень хороша, 2) хорошим регрессором можно
model3=lm(mpg~log(disp)+hp+drat,data)
summary(model3)
model2=lm(mpg~disp+hp+drat,data)
summary(model2)
model3=lm(mpg~log(disp)+log(hp)+drat,data)
summary(model3)
#3 Вводим в модель логарифмы регрессоров
model3=lm(mpg~log(disp)+hp+drat,data)
summary(model3)
#3 Вводим в модель логарифмы регрессоров
model3=lm(mpg~log(disp)+log(hp)+log(drat),data)
summary(model3)
model3=lm(mpg~log(disp)+log(hp)+log(drat),data)
summary(model3)
model3=lm(mpg~log(disp)+log(hp)+drat,data)
summary(model3)
model3=lm(mpg~log(disp)+log(hp)+log(drat),data)
summary(model3)
#Выбираем новую модель так как,ее R^2 вырос с 75% до с 82%
#Так как drat в
model4=lm(mpg~log(disp)+log(hp),data)
summary(model4)
#3 Вводим в модель логарифмы регрессоров
model3=lm(mpg~log(disp)+log(hp)+drat,data)
summary(model3)
summary(lm(log(drat)~log(disp)+log(hp),data))
summary(lm(log(disp)~log(drat)+log(hp),data))
summary(lm(log(hp)~log(drat)+log(disp),data))
summary(lm(log(drat)~log(disp)+log(hp),data))
summary(lm(log(disp)~log(drat)+log(hp),data))
model4=lm(mpg~log(dart)+log(hp),data)
model4=lm(mpg~log(drat)+log(hp),data)
model4=lm(mpg~log(drat)+log(hp),data)
summary(model4)#наилучшая модель
model4=lm(mpg~log(disp)+log(hp),data)
summary(model4)#наилучшая модель
vif(log(hp),log(drat),log(disp))
library(car)
library("lmtest")
data = na.omit(mtcars)
vif(log(hp),log(drat),log(disp))
vif(log(drat),log(disp))
model3=lm(mpg~I(log(disp))+I(log(hp))+drat,data)
summary(model3)
model3=lm(mpg~I(log(disp))+I(log(hp))+I(log(drat)),data)
summary(model3)
source("~/NIR_2023(2 Sem)/practice_2.R", echo=TRUE)
model4=lm(mpg~I(log(disp))+I(log(hp)),data)
summary(model4)#наилучшая модель
vif(I(log(drat)),I(log(disp)),I(log(hp)))
summary(lm(log(hp)~log(drat)+log(disp),data))
vif(lm(I(log(drat))~I(log(disp))+I(log(hp)),data))
vif(lm(log(disp)~log(drat)+log(hp),data))
vif(lm(I(log(hp))~I(log(drat))+I(log(disp)),data))
vif(lm(I(log(drat))~I(log(disp))+I(log(hp)),data))
vif(lm(I(log(disp))~I(log(drat))+I(log(hp)),data))
vif(lm(I(log(hp))~I(log(drat))+I(log(disp)),data))
vif(lm(I(log(drat))~I(log(disp))+I(log(hp)),data))
vif(lm(I(log(disp))~I(log(drat))+I(log(hp)),data))
vif(lm(I(log(hp))~I(log(drat))+I(log(disp)),data))
model3=lm(mpg~I(log(disp))+I(log(hp))+I(log(drat)),data)
summary(model3)
model5=lm(mpg~I(log(disp)*log(hp))+I(log(hp)),data)
summary(model5)
model6=lm(mpg~I(log(disp)*log(hp))+I(log(disp)*log(hp)),data)
summary(model6)
model5=lm(mpg~I(log(disp)*log(hp))+I(log(hp)),data)
summary(model5)
model6=lm(mpg~I(log(disp)^2)+I(log(hp)^2),data)
summary(model6)
model7=lm(mpg~I(log(disp)^2*log(hp)^2)+I(log(hp)^2),data)
summary(model6)
model7=lm(mpg~I(log(disp)^2*log(hp)^2)+I(log(hp)^2),data)
summary(model7)
model7=lm(mpg~I((log(disp)^2)*(log(hp)^2))+I(log(hp)^2),data)
summary(model7)
model7=lm(mpg~I((log(disp)^2)*(log(hp)^2))+I(log(hp)^2),data)
summary(model7)
model8=lm(mpg~disp*hp+drat,data)
summary(model8)
model8=lm(mpg~I(disp*hp)+drat,data)
summary(model8)
model9=lm(mpg~I(disp*drat)+hp,data)
summary(model9)
model9=lm(mpg~I(disp*drat)+hp,data)
summary(model9)
model10=lm(mpg~I(hp*drat)+disp,data)
summary(model10)
model5=lm(mpg~I(log(disp)*log(hp)),data)
summary(model5)
model5=lm(mpg~I(log(disp)*log(hp))+I(log(hp)),data)
summary(model5)
model8=lm(mpg~I(disp^2)+I(hp^2)+drat,data)
summary(model2)
model8=lm(mpg~I(disp^2)+I(hp^2)+drat,data)
summary(model8)
model8=lm(mpg~I(disp^2)+I(hp^2)+I(drat^2),data)
summary(model8)
model9=lm(mpg~I(disp^2*hp^2)+I(drat^2),data)
summary(model9)
model9=lm(mpg~I(disp^2*hp^2)+drat,data)
summary(model9)
new_data=swiss
new_data["disp^2"]=data$disp^2
new_data=na.omit(mtcars)
new_data["disp^2"]=data$disp^2
new_data["disp^2"]=data["disp"]^2
print(new_data["hp*disp"],new_data$hp*disp)
print(new_data["hp*disp"])
new_data=na.omit(mtcars)
new_data["disp^2"]=data["disp"]^2
new_data["hp^2"]=data["hp"]^2
new_data["drat^2"]=data["drat"]^2
new_data["drat*hp"]=data["drat"]*data["hp"]
new_data["drat*disp"]=data["drat"]*data["disp"]
new_data["hp*disp"]=data["hp"]*data["disp"]
print(new_data["hp*disp"])
print(new_data$hp*disp)
print(new_data$(hp*disp)
print(new_data$(hp*disp))
print(new_data$hp*disp)
new_data["disp^2"]=data["disp"]^2
new_data["hp^2"]=data["hp"]^2
new_data["drat^2"]=data["drat"]^2
new_data["drat*hp"]=data["drat"]*data["hp"]
new_data["drat*disp"]=data["drat"]*data["disp"]
new_data$hp*disp=data["hp"]*data["disp"]
model5=lm(mpg~I(disp*hp)+drat,data)
summary(model8)
model7=lm(mpg~I(hp*drat)+disp,data)
summary(model7)
model8=lm(mpg~I(disp^2)+I(hp^2)+I(drat^2),data)
summary(model8)
model10=lm(mpg~I(disp^2*hp^2)+I(drat^2),data)
summary(model10)
model9=lm(mpg~I(drat^2*hp^2)+disp,data)
summary(model9)
model9=lm(mpg~I(drat^2*hp^2)+I(disp^2),data)
summary(model9)
model11=lm(mpg~I(drat^2*hp^2)+I(disp^2),data)
summary(model11)
model11=lm(mpg~I(drat^2*hp^2)+I(disp),data)
summary(model11)
model5=lm(mpg~I(disp*hp)+drat,data)
summary(model5)
vif(model5)
source("~/NIR_2023(2 Sem)/practice_2.R", echo=TRUE)
model6=lm(mpg~I(disp*drat)+hp,data)
summary(model6)
vif(model6)
model11=lm(mpg~I(drat^2*hp^2)+I(disp^2),data)
summary(model11)
vif(model11)
model12=lm(mpg~I(drat^2*hp^2)+I(disp),data)
summary(model12)
vif(model12)
model13=lm(mpg~I(drat^2*disp^2)+I(hp),data)
summary(model13)
vif(model13)
model13=lm(mpg~I(drat^2*disp^2)+I(hp^2),data)
summary(model13)
vif(model13)
model14=lm(mpg~I(drat^2*disp^2)+I(hp),data)
summary(model14)
vif(model14)
model5=lm(mpg~I(disp*hp)+drat,data)
summary(model5)
vif(model5)
model6=lm(mpg~I(disp*drat)+hp,data)
summary(model6)
vif(model6)
model7=lm(mpg~I(hp*drat)+disp,data)
summary(model7)
model7=lm(mpg~I(hp*drat)+disp,data)#R^2=72%
summary(model7)
vif(model7)
model8=lm(mpg~I(disp^2)+I(hp^2)+I(drat^2),data)#R^2=71%
summary(model8)
vif(mode8)
model8=lm(mpg~I(disp^2)+I(hp^2)+I(drat^2),data)#R^2=71%
summary(model8)
vif(model8)
model9=lm(mpg~I(disp^2*hp^2)+I(drat),data)
summary(model9)
vif(model9)
model10=lm(mpg~I(disp^2*hp^2)+I(drat^2),data)
summary(model10)
vif(model10)
model11=lm(mpg~I(drat^2*hp^2)+I(disp^2),data)
summary(model11)
vif(model11)
model12=lm(mpg~I(drat^2*hp^2)+I(disp),data)
summary(model12)
vif(model12)
model13=lm(mpg~I(drat^2*disp^2)+I(hp^2),data)
summary(model13)
vif(model13)
model14=lm(mpg~I(drat^2*disp^2)+I(hp),data)
summary(model14)
vif(model14)
model11=lm(mpg~I(drat^2*hp^2)+I(disp^2),data)
summary(model11)
vif(model11)
model12=lm(mpg~I(drat^2*hp^2)+I(disp),data)
summary(model12)
vif(model12)
model13=lm(mpg~I(drat^2*disp^2)+I(hp^2),data)
summary(model13)
vif(model13)
model14=lm(mpg~I(drat^2*disp^2)+I(hp),data)
summary(model14)
vif(model14)
summary(lm(mpg~I(log(disp))+I((hp))+I(log(drat)),data))
summary(lm(mpg~I(log(disp))+I((hp))+I((drat)),data))#
summary(lm(mpg~I(log(disp))+I(log(hp))+I((drat)),data))#R^2=81%
library(car)
library("lmtest")
data = na.omit(mtcars)
#1 Исследуем линейную завимсимость регрессоров
model1=lm(mpg~cyl+disp+hp+drat,data)
vif(model1)#vif самый большой у cyl
library("lmtest")
data = na.omit(mtcars)
# Вариант 7
# Первая часть практической
"Прочитав информацию из набора данных, выполните задачи:
1. Проверьте, что в наборе данных нет линейной зависимости (построить зависимости
между переменными, указанными в варианте, и проверить, что R
2
в каждой из них
невысокий). В случае, если R
2
большой, один из таких столбцов можно исключить
из рассмотрения.
2. Постройте линейную модель зависимой переменной от указанных в варианте
регрессоров по методу наименьших квадратов (команда lm пакета lmtest в языке R).
Оценить, насколько хороша модель, согласно: 1) R
2
, 2) p-значениям каждого
коэффициента.
3. Введите в модель логарифмы регрессоров (если возможно). Сравнить модели и
выбрать наилучшую.
4. Введите в модель всевозможные произведения пар регрессоров, в том числе
квадраты регрессоров. Найдите одну или несколько наилучших моделей по доле
объяснённого разброса в данных R
2
."
library("lmtest")
data = na.omit(mtcars)
# Вариант 7
# Первая часть практической
"Прочитав информацию из набора данных, выполните задачи:
1. Проверьте, что в наборе данных нет линейной зависимости (построить зависимости
между переменными, указанными в варианте, и проверить, что R^2 в каждой из них
невысокий). В случае, если R^2 большой, один из таких столбцов можно исключить
из рассмотрения.
2. Постройте линейную модель зависимой переменной от указанных в варианте
регрессоров по методу наименьших квадратов (команда lm пакета lmtest в языке R).
Оценить, насколько хороша модель, согласно: 1) R^2, 2) p-значениям каждого
коэффициента.
3. Введите в модель логарифмы регрессоров (если возможно). Сравнить модели и
выбрать наилучшую.
4. Введите в модель всевозможные произведения пар регрессоров, в том числе
квадраты регрессоров. Найдите одну или несколько наилучших моделей по доле
объяснённого разброса в данных R^2."
# Вторая часть практической
"Для зависимости, построенной при решении практического задания №2, оцените:
1. Доверительные интервалы для всех коэффициентов в модели, p = 95%.
2. Сделайте вывод о отвержении или невозможности отвергнуть статистическую
гипотезу о том, что коэффициент равен 0.
3. Доверительный интервал для одного прогноза (p = 95%, набор значений
регрессоров выбираете сами)."
"Вторая часть практической
Для зависимости, построенной при решении практического задания №2, оцените:
1. Доверительные интервалы для всех коэффициентов в модели, p = 95%.
2. Сделайте вывод о отвержении или невозможности отвергнуть статистическую
гипотезу о том, что коэффициент равен 0.
3. Доверительный интервал для одного прогноза (p = 95%, набор значений
регрессоров выбираете сами)."
#Вторая часть практической
"Для зависимости, построенной при решении практического задания №2, оцените:
1. Доверительные интервалы для всех коэффициентов в модели, p = 95%.
2. Сделайте вывод о отвержении или невозможности отвергнуть статистическую
гипотезу о том, что коэффициент равен 0.
3. Доверительный интервал для одного прогноза (p = 95%, набор значений
регрессоров выбираете сами)."
help(data)
help(mtcars)
data
len(data)
lenght(data)
length(data)
length(data["mpg"])
qt(0.975,32)
model4=lm(mpg~I(log(disp))+I(log(hp)),data)
summary(model4)#наилучшая модель R^2=82,9%
coef(model4)
[(73.17-4.6*2.03),(73.17+4.6*2.03)]
qt(0.975,32)
stderr(model4)
coef(model4)$I(log(disp))
coef(model4)
interval <- function(qt,cof,st_er){return (cof-qr*st_er,cof+qt*st_er)}
interval(qt(0.975,32),73.17,4.6)
interval <- function(qt,cof,st_er){
list(lw=cof-qr*st_er,up=cof+qt*st_er)
return(list(lw,up))
}
interval(qt(0.975,32),73.17,4.6)
interval(crit,73.17,4.6)
crit=qt(0.975,32)
coef(model4)
interval <- function(qt,cof,st_er){
list(lw=cof-qr*st_er,up=cof+qt*st_er)
return(list(lw,up))
}
interval(crit,73.17,4.6)
interval(2.03,73.17,4.6)
interval <- function(qt,cof,st_er){
list(lw=cof-qt*st_er,up=cof+qt*st_er)
return(list(lw,up))
}
interval(2.03,73.17,4.6)
interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list("lw" = lw, "up" = up)
return(newList)
}
interval(2.03,73.17,4.6)
interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list("lw" = lw, "up" = up)
return(newList[])
}
interval(2.03,73.17,4.6)
interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list(lw, up)
return(newList[])
}
interval(2.03,73.17,4.6)
interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list("lw" = lw, "up" = up)
return(newList)
}
print(interval(2.03,73.17,4.6))
summary(interval(2.03,73.17,4.6))
str(interval(2.03,73.17,4.6))
str(interval(crit,73.17,4.6))
s=interval(crit,73.17,4.6)
print("[",s['lw'],", ", s['up'],"]")
s=interval(crit,73.17,4.6)
print("[",s["lw"],", ", s["up"],"]")
s=interval(crit,73.17,4.6)
print(s["lw"],s["up"])
s=interval(crit,73.17,4.6)
sprintf("[% , %]",s[["up"]],s[["lw"]])
s=interval(crit,73.17,4.6)
sprintf("[% , %]",str(s[["up"]]),str(s[["lw"]]))
s=interval(crit,73.17,4.6)
sprintf("[% , %]",str(s["up"]),str(s["lw"]))
sprintf("[% , %]",s["up"],s["lw"])
sprintf("[%s , %s]",s["up"],s["lw"])
coef(model4)
summary(model4)#наилучшая модель R^2=82,9%
interval=count_interval(crit,-6.99,1.4)
count_interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list("lw" = lw, "up" = up)
return(newList)
}
interval=count_interval(crit,73.17,4.6)
sprintf("[%s , %s]",interval["up"],interval["lw"])
interval=count_interval(crit,-6.99,1.4)
sprintf("[%s , %s]",interval["up"],interval["lw"])
summary(model4)#наилучшая модель R^2=82,9%
interval=count_interval(crit,-3.3,1.8)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интревал для log(hp)
interval=count_interval(crit,73.17,4.6)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интервал для свободного коэф
interval=count_interval(crit,73.17,4.6)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интервал для свободного коэф
# Отвергаем гипотезу о том, что этот коэффициент может быть равен 0, на уровне значимости 5%.
new.data = data.frame(log(disp) = 10, log(h) = 15)
new.data = data.frame(disp = 10, h = 15)
predict(model4, new.data, interval = "confidence")
new.data = data.frame(disp = 10, hp = 15)
predict(model4, new.data, interval = "confidence")
"__________________________________________________________________________________"
#Вторая часть практической
"Для зависимости, построенной при решении практического задания №2, оцените:
1. Доверительные интервалы для всех коэффициентов в модели, p = 95%.
2. Сделайте вывод о отвержении или невозможности отвергнуть статистическую
гипотезу о том, что коэффициент равен 0.
3. Доверительный интервал для одного прогноза (p = 95%, набор значений
регрессоров выбираете сами)."
#1,2) Доверительные интервалы для каждого коэфицента с p=95% и проверка статистической гипотезы коэф = 0
model4=lm(mpg~I(log(disp))+I(log(hp)),data)
summary(model4)#наилучшая модель R^2=82,9%
crit=qt(0.975,32)# t-критериq Стьюдента = 2.03
coef(model4)
count_interval <- function(qt,cof,st_er){
lw <- cof-qt*st_er
up <- cof+qt*st_er
newList <- list("lw" = lw, "up" = up)
return(newList)
}
interval=count_interval(crit,73.17,4.6)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интервал для свободного коэф
# Отвергаем гипотезу о том, что этот коэффициент может быть равен 0, на уровне значимости 5% (нет 0 в этом интервале)
interval=count_interval(crit,-6.99,1.4)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интревал для log(disp)
# Отвергаем гипотезу о том, что этот коэффициент может быть равен 0, на уровне значимости 5% (нет 0 в этом интервале)
interval=count_interval(crit,-3.3,1.8)
sprintf("[%s , %s]",interval["up"],interval["lw"])#Интревал для log(hp)
# Отвергаем гипотезу о том, что этот коэффициент может быть равен 0, на уровне значимости 5% (нет 0 в этом интервале)
#3 Доверительный интервал для одного прогноза
new.data = data.frame(disp = 10, hp = 15)
predict(model4, new.data, interval = "confidence")
#Доверительный интервал для одного прогноза [43.39083, 52.86688]
